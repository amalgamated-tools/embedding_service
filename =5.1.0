Defaulting to user installation because normal site-packages is not writeable
Collecting sentence-transformers
  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata
     - 16.3 kB 76.8 MB/s 0:00:00
Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)
  Downloading transformers-4.56.1-py3-none-any.whl.metadata
     - 42.2 kB 198.5 MB/s 0:00:00
Collecting tqdm (from sentence-transformers)
  Downloading tqdm-4.67.1-py3-none-any.whl.metadata
     - 57.7 kB 203.7 MB/s 0:00:00
Collecting torch>=1.11.0 (from sentence-transformers)
  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata
     - 30.7 kB 249.2 MB/s 0:00:00
Collecting scikit-learn (from sentence-transformers)
  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
     - 11.8 kB 67.1 MB/s 0:00:00
Collecting scipy (from sentence-transformers)
  Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
     - 62.0 kB 226.6 MB/s 0:00:00
Collecting huggingface-hub>=0.20.0 (from sentence-transformers)
  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata
     - 14.8 kB 148.8 MB/s 0:00:00
Collecting Pillow (from sentence-transformers)
  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata
     - 9.0 kB ? 0:00:00
Requirement already satisfied: typing_extensions>=4.5.0 in /home/runner/.local/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)
Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)
  Downloading filelock-3.19.1-py3-none-any.whl.metadata
     - 2.1 kB ? 0:00:00
Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)
  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata
     - 10.4 kB 7.5 MB/s 0:00:00
Requirement already satisfied: packaging>=20.9 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.0)
Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)
Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)
Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)
  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
     - 4.7 kB ? 0:00:00
Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch>=1.11.0->sentence-transformers) (68.1.2)
Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)
  Downloading sympy-1.14.0-py3-none-any.whl.metadata
     - 12.8 kB 115.0 MB/s 0:00:00
Collecting networkx (from torch>=1.11.0->sentence-transformers)
  Downloading networkx-3.5-py3-none-any.whl.metadata
     - 6.3 kB ? 0:00:00
Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)
Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata
     - 1.7 kB ? 0:00:00
Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
     - 1.7 kB ? 0:00:00
Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
     - 1.7 kB ? 0:00:00
Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata
     - 1.8 kB ? 0:00:00
Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata
     - 1.7 kB ? 0:00:00
Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
     - 1.7 kB ? 0:00:00
Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata
     - 1.7 kB ? 0:00:00
Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata
     - 1.8 kB ? 0:00:00
Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
     - 1.8 kB ? 0:00:00
Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata
     - 7.0 kB ? 0:00:00
Collecting nvidia-nccl-cu12==2.27.3 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
     - 2.0 kB ? 0:00:00
Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
     - 1.8 kB ? 0:00:00
Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata
     - 1.7 kB ? 0:00:00
Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.11.0->sentence-transformers)
  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata
     - 1.7 kB ? 0:00:00
Collecting triton==3.4.0 (from torch>=1.11.0->sentence-transformers)
  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata
     - 1.7 kB ? 0:00:00
Requirement already satisfied: numpy>=1.17 in /home/runner/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.3)
Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)
  Downloading regex-2025.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata
     - 40.5 kB 229.8 MB/s 0:00:00
Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)
  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
     - 6.8 kB ? 0:00:00
Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)
  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
     - 4.1 kB ? 0:00:00
Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)
  Downloading joblib-1.5.2-py3-none-any.whl.metadata
     - 5.6 kB ? 0:00:00
Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)
  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata
     - 13.8 kB 164.2 MB/s 0:00:00
Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)
  Downloading mpmath-1.3.0-py3-none-any.whl.metadata
     - 8.6 kB ? 0:00:00
Downloading sentence_transformers-5.1.0-py3-none-any.whl
   - 483.4 kB 208.1 MB/s 0:00:00
Downloading huggingface_hub-0.35.0-py3-none-any.whl
   - 563.4 kB 213.8 MB/s 0:00:00
Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl
   - 887.9 MB 230.1 MB/s 0:00:10
Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl
   - 594.3 MB 223.3 MB/s 0:00:05
Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl
   - 10.2 MB 195.9 MB/s 0:00:00
Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl
   | 88.0 MB 232.8 MB/s 0:00:00
Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl
   - 954.8 kB 214.9 MB/s 0:00:00
Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl
   \ 706.8 MB 247.3 MB/s 0:00:06
Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl
   - 193.1 MB 233.6 MB/s 0:00:01
Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl
   - 1.2 MB 157.4 MB/s 0:00:00
Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl
   \ 63.6 MB 223.0 MB/s 0:00:00
Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl
   / 267.5 MB 230.0 MB/s 0:00:02
Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl
   / 288.2 MB 223.9 MB/s 0:00:03
Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl
   / 287.2 MB 240.4 MB/s 0:00:02
Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl
   | 322.4 MB 216.6 MB/s 0:00:02
Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl
   | 39.3 MB 211.9 MB/s 0:00:00
Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl
   - 90.0 kB 235.3 MB/s 0:00:00
Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl
   \ 155.6 MB 172.3 MB/s 0:00:01
Downloading tqdm-4.67.1-py3-none-any.whl
   - 78.5 kB 181.3 MB/s 0:00:00
Downloading transformers-4.56.1-py3-none-any.whl
   \ 11.6 MB 179.7 MB/s 0:00:00
Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl
   - 6.6 MB 158.2 MB/s 0:00:00
Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl
   - 9.5 MB 166.6 MB/s 0:00:00
Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl
   | 35.7 MB 234.5 MB/s 0:00:00
Downloading fsspec-2025.9.0-py3-none-any.whl
   - 199.3 kB 153.2 MB/s 0:00:00
Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
   - 3.2 MB 159.8 MB/s 0:00:00
Downloading joblib-1.5.2-py3-none-any.whl
   - 308.4 kB 184.9 MB/s 0:00:00
Downloading regex-2025.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl
   - 802.0 kB 173.7 MB/s 0:00:00
Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
   - 485.8 kB 157.2 MB/s 0:00:00
Downloading sympy-1.14.0-py3-none-any.whl
   - 6.3 MB 165.1 MB/s 0:00:00
Downloading threadpoolctl-3.6.0-py3-none-any.whl
   - 18.6 kB 103.7 MB/s 0:00:00
Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
   - 3.3 MB 156.9 MB/s 0:00:00
Downloading filelock-3.19.1-py3-none-any.whl
   - 16.0 kB 91.4 MB/s 0:00:00
Downloading networkx-3.5-py3-none-any.whl
   - 2.0 MB 192.9 MB/s 0:00:00
Downloading mpmath-1.3.0-py3-none-any.whl
   - 536.2 kB 205.7 MB/s 0:00:00
Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, tqdm, threadpoolctl, sympy, scipy, safetensors, regex, Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, joblib, hf-xet, fsspec, filelock, scikit-learn, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence-transformers
Successfully installed Pillow-11.3.0 filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.35.0 joblib-1.5.2 mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 regex-2025.9.1 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.2 sentence-transformers-5.1.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.0 torch-2.8.0 tqdm-4.67.1 transformers-4.56.1 triton-3.4.0
